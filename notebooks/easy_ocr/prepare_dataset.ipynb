{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 49.6M  100 49.6M    0     0  33.4M      0  0:00:01  0:00:01 --:--:-- 33.4M\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://download.slipenko.com/mzhn-team-sochi/yolov8-price-tag-detection-06-04.pt -o yolov8-price-tag-detection.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   289  100   289    0     0   6369      0 --:--:-- --:--:-- --:--:--  6422\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://download.slipenko.com/mzhn-team-sochi/yolov8-price-tag-detection-dataset-06-04.yaml --create-dirs -o ./datasets/yolov8-price-tag-detection-dataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.utils import check_det_dataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataset = check_det_dataset(\"./datasets/yolov8-price-tag-detection-dataset.yaml\")\n",
    "\n",
    "\n",
    "def list_files(directory):\n",
    "    directory = Path(directory)\n",
    "    files = [file for file in directory.iterdir() if file.is_file()]\n",
    "    return files\n",
    "\n",
    "\n",
    "files = []\n",
    "files += list_files(dataset['train'])\n",
    "files += list_files(dataset['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 descriptions, 1 price_fraction, 1 price_whole, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 6 descriptions, 6 price_wholes, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 544x640 1 description, 1 price_fraction, 1 price_whole, 9.2ms\n",
      "Speed: 1.2ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 512x640 2 descriptions, 1 price_fraction, 2 price_wholes, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 18 descriptions, 14 price_wholes, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 descriptions, 10 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 descriptions, 7 price_wholes, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 10 descriptions, 7 price_fractions, 10 price_wholes, 10.2ms\n",
      "Speed: 1.7ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 6 descriptions, 6 price_wholes, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 description, 1 price_whole, 8.6ms\n",
      "Speed: 1.2ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 3 descriptions, 3 price_fractions, 3 price_wholes, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 descriptions, 9 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 2 descriptions, 1 price_whole, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 512x640 1 description, 1 price_fraction, 1 price_whole, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 5 descriptions, 3 price_wholes, 8.8ms\n",
      "Speed: 2.2ms preprocess, 8.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 2 descriptions, 1 price_fraction, 1 price_whole, 8.7ms\n",
      "Speed: 1.9ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 7 descriptions, 2 price_fractions, 8 price_wholes, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 (no detections), 8.8ms\n",
      "Speed: 1.8ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 10 descriptions, 10 price_fractions, 10 price_wholes, 10.3ms\n",
      "Speed: 1.8ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 description, 1 price_fraction, 1 price_whole, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 352x640 3 descriptions, 3 price_wholes, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 352x640 1 price_fraction, 1 price_whole, 7.4ms\n",
      "Speed: 1.0ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 640x480 (no detections), 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 descriptions, 1 price_fraction, 1 price_whole, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 4 descriptions, 5 price_wholes, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 descriptions, 4 price_wholes, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 descriptions, 5 price_fractions, 8 price_wholes, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 descriptions, 5 price_wholes, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 description, 1 price_fraction, 1 price_whole, 8.3ms\n",
      "Speed: 2.8ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 1 description, 1 price_fraction, 1 price_whole, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 10.4ms\n",
      "Speed: 1.7ms preprocess, 10.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 9 descriptions, 10 price_wholes, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 descriptions, 5 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 descriptions, 2 price_fractions, 2 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 descriptions, 3 price_wholes, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 2 descriptions, 2 price_wholes, 8.8ms\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 2 descriptions, 2 price_fractions, 2 price_wholes, 10.2ms\n",
      "Speed: 2.1ms preprocess, 10.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 9 descriptions, 7 price_fractions, 9 price_wholes, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 10.3ms\n",
      "Speed: 1.9ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 9.8ms\n",
      "Speed: 1.6ms preprocess, 9.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 512x640 2 descriptions, 1 price_fraction, 2 price_wholes, 8.4ms\n",
      "Speed: 1.2ms preprocess, 8.4ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 7 descriptions, 8 price_wholes, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 descriptions, 4 price_wholes, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 320x640 1 description, 1 price_whole, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 640x480 1 description, 2 price_wholes, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 5 descriptions, 6 price_wholes, 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 3 descriptions, 3 price_wholes, 8.7ms\n",
      "Speed: 1.3ms preprocess, 8.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 10.3ms\n",
      "Speed: 1.5ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 3 descriptions, 2 price_fractions, 4 price_wholes, 8.5ms\n",
      "Speed: 1.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 descriptions, 2 price_fractions, 2 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 descriptions, 5 price_wholes, 8.1ms\n",
      "Speed: 1.3ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 description, 1 price_whole, 9.3ms\n",
      "Speed: 1.7ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 288x640 1 description, 1 price_fraction, 1 price_whole, 7.8ms\n",
      "Speed: 1.3ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x640 3 descriptions, 3 price_fractions, 3 price_wholes, 10.5ms\n",
      "Speed: 1.8ms preprocess, 10.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 320x640 2 descriptions, 2 price_fractions, 3 price_wholes, 7.5ms\n",
      "Speed: 1.1ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 544x640 2 descriptions, 1 price_fraction, 1 price_whole, 9.1ms\n",
      "Speed: 1.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 640x640 1 description, 1 price_fraction, 1 price_whole, 10.2ms\n",
      "Speed: 1.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 descriptions, 1 price_fraction, 1 price_whole, 8.2ms\n",
      "Speed: 1.0ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 9 descriptions, 8 price_wholes, 8.5ms\n",
      "Speed: 1.3ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 descriptions, 3 price_wholes, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 descriptions, 7 price_wholes, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 description, 1 price_fraction, 1 price_whole, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x640 2 descriptions, 1 price_fraction, 1 price_whole, 10.3ms\n",
      "Speed: 1.7ms preprocess, 10.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 (no detections), 8.6ms\n",
      "Speed: 1.3ms preprocess, 8.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 384x640 1 description, 1 price_fraction, 1 price_whole, 8.2ms\n",
      "Speed: 0.9ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 description, 1 price_fraction, 1 price_whole, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 descriptions, 1 price_fraction, 4 price_wholes, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 2 descriptions, 2 price_wholes, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 descriptions, 10 price_wholes, 8.1ms\n",
      "Speed: 1.2ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 descriptions, 1 price_fraction, 4 price_wholes, 8.1ms\n",
      "Speed: 1.4ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "\n",
    "model = YOLO('yolov8-price-tag-detection.pt')\n",
    "\n",
    "BBOX_OCR_PADDING = 10\n",
    "\n",
    "for file in files:\n",
    "    img = cv2.imread(str(file))\n",
    "    results = model(img)\n",
    "    detections = sv.Detections.from_ultralytics(results[0])\n",
    "\n",
    "    detections = sorted(\n",
    "        [(bbox, confidence, class_id) for bbox, confidence, class_id in\n",
    "         zip(detections.xyxy, detections.confidence, detections.class_id)],\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "\n",
    "    description_img, price_whole_img, price_fraction_img = None, None, None\n",
    "\n",
    "    for bbox, confidence, class_id in detections:\n",
    "        class_name = model.names[class_id]\n",
    "        x_min, y_min, x_max, y_max = map(int, bbox[:4])\n",
    "\n",
    "        x_min, y_min = max(x_min - BBOX_OCR_PADDING, 0), max(y_min - BBOX_OCR_PADDING, 0)\n",
    "        x_max, y_max = min(x_max + BBOX_OCR_PADDING, img.shape[1]), min(y_max + BBOX_OCR_PADDING, img.shape[0])\n",
    "\n",
    "        cropped_image = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        if class_name == 'description' and description_img is None:\n",
    "            description_img = cropped_image\n",
    "        elif class_name == 'price_whole' and price_whole_img is None:\n",
    "            price_whole_img = cropped_image\n",
    "        elif class_name == 'price_fraction' and price_fraction_img is None:\n",
    "            price_fraction_img = cropped_image\n",
    "\n",
    "        if description_img is not None and price_whole_img is not None and price_fraction_img is not None:\n",
    "            break\n",
    "\n",
    "    if description_img is not None:\n",
    "        cv2.imwrite(f'dataset/description_{file.name}', description_img)\n",
    "    \n",
    "    if price_whole_img is not None:\n",
    "        cv2.imwrite(f'dataset/price_whole_{file.name}', price_whole_img)\n",
    "    \n",
    "    if price_fraction_img is not None:\n",
    "        cv2.imwrite(f'dataset/price_fraction_{file.name}', price_fraction_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "files = list_files('dataset')\n",
    "\n",
    "results = []\n",
    "\n",
    "reader = easyocr.Reader(['ru', 'en'])\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        text_result = reader.readtext(str(file), paragraph=True)\n",
    "        # Concatenate extracted text\n",
    "        description = ' '.join([text[1] for text in text_result])\n",
    "        results.append((file.name, description))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file.name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_path = 'output.csv'  # Update this path\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['filename', 'words'])\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EasyOCR'...\n",
      "remote: Enumerating objects: 2736, done.\u001b[K\n",
      "remote: Total 2736 (delta 0), reused 0 (delta 0), pack-reused 2736\u001b[K\n",
      "Receiving objects: 100% (2736/2736), 157.83 MiB | 3.63 MiB/s, done.\n",
      "Resolving deltas: 100% (1664/1664), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/JaidedAI/EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp custom_data_train.yaml EasyOCR/trainer/config_files/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
